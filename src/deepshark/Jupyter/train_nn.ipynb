{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd487af-dea9-4127-b094-4c0c1b27c30c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a Neural Network\n",
    "\n",
    "Use PyTorch to train a simple neural network on the data recorded between heuristic MTAG players.\n",
    "\n",
    "### Convert Recorded Tournaments to Neural Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba843c3f-9799-4f61-ac2b-11ba7785470e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import struct\n",
    "\n",
    "training_directory = Path(\"../../../recorded_games/2024-01-08/mtag/converted\")\n",
    "training_directory.mkdir(parents=True, exist_ok=True)\n",
    "train_data_directory = Path(\"../../../recorded_games/2024-01-08/mtag/\")\n",
    "\n",
    "test_directory = Path(\"../../../recorded_games/2024-01-08/mtag_test_data/converted\")\n",
    "test_directory.mkdir(parents=True, exist_ok=True)\n",
    "test_data_directory = Path(\"../../../recorded_games/2024-01-08/mtag_test_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7954331-5c4f-4063-91b7-8d8bed8c4feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create list of all recorded tournaments in directory\n",
    "train_files = [join(train_data_directory, f) for f in listdir(\n",
    "        train_data_directory) if isfile(join(train_data_directory, f))]\n",
    "\n",
    "test_files = [join(test_data_directory, f) for f in listdir(\n",
    "        test_data_directory) if isfile(join(test_data_directory, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974fefec-3e44-4185-8fe6-77dfc9bb139b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Initialize and test C shared library\n",
    "###############################################################################\n",
    "import ctypes\n",
    "# Location of C shared library\n",
    "c_lib = ctypes.CDLL(\"../../Cpp/lib/lib_deepshark.so\")\n",
    "# %% Set data types of test C function's arguments and return value\n",
    "add_ints = c_lib.add_ints\n",
    "add_ints.argtypes = [ctypes.c_int, ctypes.c_int]\n",
    "add_ints.restype = ctypes.c_int  # C function returns integer\n",
    "# Test C function\n",
    "result = add_ints(4, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f350e954-5e30-4140-a934-088f337979d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initalize C function to convert tournament results\n",
    "###############################################################################\n",
    "write_nn_vector_data = c_lib.write_nn_vector_data\n",
    "write_nn_vector_data.argtypes = [ctypes.POINTER(ctypes.c_char), ctypes.POINTER(ctypes.c_char)]\n",
    "write_nn_vector_data.restype = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e0bd20-7af2-4ef1-965b-e4b4ed51ab2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Convert recorded tournaments to neural network inputs and labels\n",
    "def convert_files(data_files, conv_dir):\n",
    "    for tfile in data_files:\n",
    "        b_r_fn = tfile.encode(\"utf-8\")  # create byte objects from the strings\n",
    "        tfilew = str(conv_dir / \"converted_file.bin\")\n",
    "        b_w_fn = tfilew.encode(\"utf-8\")\n",
    "        read_filename = ctypes.c_char_p(b_r_fn)\n",
    "        write_filename = ctypes.c_char_p(b_w_fn)\n",
    "        write_nn_vector_data(read_filename, write_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75d8b3b-1a5d-49a7-9734-8bdf2ed823ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert_files(train_files, training_directory)\n",
    "#convert_files(test_files, test_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e620f7-ca1d-4b08-8607-e0b13d2ccb33",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create custom PyTorch datasets and dataloaders for binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45cb690-8a57-4775-92a7-87b38733c0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PokerDataset(Dataset):\n",
    "        def __init__(self, converted_file):\n",
    "            self.data_file = Path(converted_file)\n",
    "            self.file_size_in_bytes = self.data_file.stat().st_size\n",
    "            self.item_size_in_bytes = 8 * 68  # Array of 68 doubles per record\n",
    "                        \n",
    "        def __len__(self):\n",
    "            return int(self.file_size_in_bytes / self.item_size_in_bytes)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            with open(self.data_file, mode='rb') as f:\n",
    "                f.seek(idx*self.item_size_in_bytes)\n",
    "                item = f.read(self.item_size_in_bytes)\n",
    "            vector = struct.unpack(\"<\"+68*\"d\", item)\n",
    "            data = torch.tensor(vector[0:60])\n",
    "            label = torch.tensor(vector[60:])\n",
    "            return data, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f070f2e-aca6-444a-9a01-1c3d1a17d365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_data = PokerDataset(training_directory / \"converted_file.bin\")\n",
    "test_data = PokerDataset(test_directory / \"converted_file.bin\")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c3e922-c75c-410a-bf3a-bb777b0d7381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325928"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81278b2-a9f1-4b80-9be1-8be0475540e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5714,\n",
       "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "         0.2857, 0.0000, 0.0000, 0.0000, 1.0000, 0.2857, 0.0000, 0.0000, 1.0000,\n",
       "         0.0000, 0.5714, 0.0000, 1.0000, 0.0000, 0.0000, 0.0020, 0.0020, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.1000]),\n",
       " tensor([0., 0., 0., 0., 1., 0., 0., 0.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[162964-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbec61-9f3a-41d7-a0d4-a89830fe7c6b",
   "metadata": {},
   "source": [
    "### Define Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2df36a4-0383-4e7d-bcf3-a3361f6b54ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509776c2-7660-43b2-bcf3-54688eba2d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba1d633-2690-4d5b-bdec-65be6b06bea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(60, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        action_logits = logits[:,:-1]\n",
    "        ##action_probs = nn.Softmax(dim=1)(action_logits)\n",
    "        bet_logit = logits[:, -1]\n",
    "        scaled_bet = nn.Sigmoid()(bet_logit)\n",
    "        return action_logits, scaled_bet\n",
    "        #return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "425a1d5b-1d8c-43d3-bb5c-93c0d547ea8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=60, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90114989-cb1b-4dab-8081-23eb0d3c7dda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6648\n",
      "6648\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)\n",
    "print(pytorch_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2824a428-d9fa-4f02-9926-301c5f1e1d32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.2712, -0.1416, -0.2987, -0.0798,  0.1598, -0.2010, -0.1904],\n",
      "        [-0.2869, -0.1468, -0.2904, -0.0869,  0.1756, -0.2029, -0.1872],\n",
      "        [-0.2634, -0.1240, -0.3076, -0.0506,  0.1400, -0.1931, -0.2147]],\n",
      "       grad_fn=<SliceBackward0>), tensor([0.5551, 0.5554, 0.5535], grad_fn=<SigmoidBackward0>))\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(3, 60, device=device)\n",
    "output = model(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "005e8981-6492-4b68-aa98-7744d3723dad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(output[0].shape)\n",
    "print(output[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c0b0a-afca-4009-b47b-d698a7e827c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d42ac5-4954-47b3-99f9-950cf80ea061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "epochs = 100\n",
    "weights = torch.tensor([5,5,5,5,0.1,5,5])\n",
    "action_loss_fn = nn.CrossEntropyLoss(weights)\n",
    "bet_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88def103-f5fa-4840-80eb-f05eff734b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff3cffe6-133c-4e88-99f0-d4ca43f9a27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(pred, y):\n",
    "    weight = 0.5\n",
    "    actions_pred = pred[0]\n",
    "    actions_y = y[:, :-1]\n",
    "    bet_pred = pred[1]\n",
    "    bet_y = y[:, -1]\n",
    "    loss = weight * action_loss_fn(actions_pred, actions_y) + (1. - weight) * bet_loss_fn(bet_pred, bet_y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17d8ec1a-38ed-4742-b3a6-13076d892bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred[0].argmax(1) == y[:, :-1].argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857ec6a-e138-44e9-824f-553ac7040667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = Path(\"../../../recorded_games/models\")\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    torch.save(model.state_dict(), os.path.join(str(model_dir), 'epoch-{}.pt'.format(t)))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418c53be-6cef-4094-b1fd-bca64020906c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=60, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"../../../recorded_games/models/epoch-61.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be85997a-27ae-4597-968b-2b314667816a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 14.2165,   1.3539,  -3.2450,   6.0915,   1.8464, -14.3288,  -8.8218]],\n",
       "        grad_fn=<SliceBackward0>),\n",
       " tensor([0.7331], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = torch.rand(1, 60, device=device)\n",
    "model(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e8e359-64a5-453e-8885-d6e31920b7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_input = torch.rand(1, 60, device=device)\n",
    "traced_script_module = torch.jit.trace(model, example_input)\n",
    "traced_script_module.save(\"traced_poker_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e4c43d-02ac-4a94-ab75-11364923f07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150528"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*224*224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcfd7c-0c17-4ddd-8f2e-cbfeffbea2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
